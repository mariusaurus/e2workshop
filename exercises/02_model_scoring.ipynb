{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Scoring Models\n",
    "\n",
    "The following notebook will demonstrate how to use Earth-2 MIP to perform a scoring\n",
    "workflow to assess the accuracy of AI models using ERA5 reanalysis data as the\n",
    "ground truth. This can then be extended to score custom models placed into the model\n",
    "registry. Usually, you'd be using file from disk, eg a from a HDF5 datasource. The expected\n",
    "format of this data would be a file containing a full year worth of data, which would be too\n",
    "large to ship for the purpose os a workshop. We will therefore use the CDS datasource\n",
    "accessing cached files.\n",
    "\n",
    "In summary this notebook will cover the following topics:\n",
    "\n",
    "- Implementing a basic scoring workflow in Earth-2 MIP\n",
    "- HDF5 datasource and the expected data format of the H5 files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up HDF5 data\n",
    "The first step of scoring is handling the target data. One could simply use the\n",
    "CDSDatasource to download target data on the fly, but depending on how comprehensive\n",
    "the scoring is, this can prove quite slow.\n",
    "Additionally, many scoring pipelines require on-prem data.\n",
    "Thus, this will demonstrate how to use the HDF5 datasource.\n",
    "The HDF5 data source assumes that the data to be loaded is stored in the general form:\n",
    "\n",
    "-  year.h5\n",
    "      | - field (time, channels, grid)\n",
    "\n",
    "For DLWP which requires 7 channels with a time-step size of 12 hours, an H5 file will\n",
    "have the following form of data for an entire year:\n",
    "\n",
    "-  2017.h5\n",
    "      | - field (730, 7, 720, 1440)\n",
    "-  2016.h5\n",
    "      | - field (730, 7, 720, 1440)\n",
    "-  2015.h5\n",
    "      | - field (730, 7, 720, 1440)\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>There is some flexibility with the dimensions of the data in the H5 files. The time\n",
    "  dimension may be some factor of 12 (such as 6hr dt or 4hr dt) and the fields may\n",
    "  contain additional channels not needed by the model. The data source will select the\n",
    "  necessary data for the model. Additionally, the later two dims have some flexibility\n",
    "  with regridding.</p></div>\n",
    "\n",
    "One option to build these H5 files from scratch is to use the ERA5 mirror scripts\n",
    "provided in [Modulus](https://github.com/NVIDIA/modulus/tree/main/examples/weather/dataset_download).\n",
    "For the rest of this tutorial, it is assumed that 2017.h5 is present for the full year.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "Having discussed the HDF5 data source, the next step is to load our model we wish to score.\n",
    "In this tutorial we will have cached data for FourCastNet SFNO (fcnv2_sm) and for DLWP.\n",
    "Take note of the `e2mip://` which will direct Earth-2 MIP to load a known model package.\n",
    "FourcastNet AFNO (fcn) can be selected as well, note though that this will trigger some\n",
    "downloads from CDS which might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from modulus.distributed import DistributedManager\n",
    "\n",
    "from earth2mip import registry\n",
    "from earth2mip.networks import dlwp, fcnv2_sm, fcn\n",
    "\n",
    "model_name = 'dlwp' # 'dlwp', 'fcnv2_sm', 'fcn'\n",
    "\n",
    "device = DistributedManager().device\n",
    "package = registry.get_model(f\"e2mip://{model_name}\")\n",
    "if model_name == 'dlwp':\n",
    "    model = dlwp.load(package, device=device)\n",
    "elif model_name == 'fcnv2_sm':\n",
    "    model = fcnv2_sm.load(package, device=device)\n",
    "elif model_name == 'fcn':\n",
    "    model = fcn.load(package, device=device)\n",
    "else:\n",
    "    raise ValueError(f'model {model_name} not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 Datasource\n",
    "With the H5 files properly formatted, a H5 datasource could now get defined.\n",
    "Find some commented code of how this would look like.\n",
    "Defining the HDF5 data source requires two items: a root directory location of the H5\n",
    "files as well as some metadata.\n",
    "The metadata is a JSON/dictionary object that helps Earth-2 MIP index the H5 file.\n",
    "Typically, this can be done by placing a `data.json` file next to the H5 files.\n",
    "See [this documentation](https://github.com/NVIDIA/earth2mip/blob/f44c580ccc3d98bf349fe97823bb1540e532c80d/earth2mip/initial_conditions/hdf5.py#L38)\n",
    "for more details on how to set up input data correctly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from earth2mip.initial_conditions import cds\n",
    "\n",
    "# h5_folder = '/e2ws_data/era5_73var'\n",
    "# datasource = hdf5.DataSource.from_path(\n",
    "#     root=h5_folder, channel_names=model.channel_names\n",
    "# )\n",
    "\n",
    "\n",
    "# Test to see if our datasource is working\n",
    "datasource = cds.DataSource(model.in_channel_names)\n",
    "time = datetime.datetime(2017, 8, 24, 12)\n",
    "out = datasource[time]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Scoring\n",
    "With the datasource and model loaded, scoring can now be performed.\n",
    "To score, we will run 4 day forecasts at 30 day intervals.\n",
    "For research, one would typically want this to be much more comprehensive\n",
    "so feel free to customize for your use case.\n",
    "To avoid massively inflating the data requirements we limited this task to\n",
    "two four day hindcasts, much larger sets can also be analysed in seconds or minutes.\n",
    "\n",
    "The `score_deterministic` API provides a simple way to calculate RMSE and ACC scores.\n",
    "ACC scores require climatology which is beyond the scope of this example, thus zero\n",
    "values will be provided and only the RMSE will be of concern.\n",
    "This function will save the results of every inference run into a CSV file which\n",
    "can then be pose process using some of the utility functions Earth-2 MIP provides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from earth2mip.inference_medium_range import save_scores, time_average_metrics\n",
    "import numpy as np\n",
    "\n",
    "# Use 2 initializations.\n",
    "time = datetime.datetime(2017, 8, 24, 12)\n",
    "initial_times = [\n",
    "    time + datetime.timedelta(days=30 * i, hours=6 * i) for i in range(2)\n",
    "]  # modify here to change the initializations\n",
    "\n",
    "# Output directoy, delete old scoring file if present\n",
    "output_dir = \"outputs/02_model_scoring\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "if os.path.exists(output_dir + '/0.csv'):\n",
    "    os.remove(output_dir + '/0.csv')\n",
    "\n",
    "output = save_scores(\n",
    "    model,\n",
    "    n=16,  # 6 hour timesteps (16*6/24 = 4-day forecast)\n",
    "    initial_times=initial_times,\n",
    "    data_source=datasource,\n",
    "    time_mean=np.zeros((len(model.in_channel_names), 721, 1440)),\n",
    "    output_directory=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "The last step is any post processing / IO that is desired.\n",
    "Typically, it is recommended to save the output dataset to a netCDF file for further processing.\n",
    "Let's plot the RMSE of the z500 (geopotential at pressure level 500) field.\n",
    "\n",
    "Hint: if you receive `ValueError: cannot convert a DataFrame with a non-unique MultiIndex into xarray`,\n",
    "go to `output_dir` (should be located under `outputs/02_model_scoring/`), delete the file `0.csv` and \n",
    "re-run the inference cell above once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from earth2mip.forecast_metrics_io import read_metrics\n",
    "\n",
    "series = read_metrics(output_dir)\n",
    "dataset = time_average_metrics(series)\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "channels = [\"z500\", \"t2m\", \"t850\"]\n",
    "t = dataset.lead_time / pd.Timedelta(\"1 h\")\n",
    "for i, channel in enumerate(channels):\n",
    "    y = dataset.rmse.sel(channel=channel)\n",
    "    axs[i].plot(t[1:], y[1:])  # Ignore first output as that's just initial condition.\n",
    "    axs[i].set_xlabel(\"Lead Time (hours)\")\n",
    "    axs[i].set_ylabel(\"RMSE\")\n",
    "    axs[i].set_title(f\"{model_name} {channel} RMSE 2017\")\n",
    "\n",
    "plt.savefig(f\"{output_dir}/dwlp_rmse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes this introductory notebook on basic scoring of models in Earth-2 MIP,\n",
    "which is founational for comparing the performance of different models.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
