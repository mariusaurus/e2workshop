{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Diagnostic Models for Precipitation\n",
    "\n",
    "The following notebook will demonstrate how to use diagnostic models inside of Earth-2\n",
    "MIP for transforming outputs of global weather models into different quantities of\n",
    "interest. More information on diagnostics can be found in the [user guide](https://nvidia.github.io/earth2mip/userguide/diagnostic.html).\n",
    "\n",
    "In summary this notebook will cover the following topics:\n",
    "\n",
    "- Loading a built in diagnostic model for predicting total precipitation\n",
    "- Combining the diagnostic model with a prognostic model using the DiangosticLooper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Diagnostic Models\n",
    "Loading diagnostic models is similar to prognostic models, but presently use a\n",
    "slightly different API. In this example we will using the built in AFNO FourCast Net\n",
    "to serve as the underlying prognostic model that will drive the time-ingration. The\n",
    ":code:`PrecipitationAFNO` model will then be used to \"post-process\" the outputs of\n",
    "this model to predict precipitation. The key API to load a diagnostic model is the\n",
    ":code:`load_diagnostic(package)` function which takes a model package in. If you're\n",
    "interested in using the built in model package (i.e. checkpoint), then the\n",
    ":code:`load_package()` function can do this for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from modulus.distributed.manager import DistributedManager\n",
    "from earth2mip.networks import get_model\n",
    "from earth2mip.diagnostic import PrecipitationAFNO\n",
    "\n",
    "device = DistributedManager().device\n",
    "\n",
    "print(\"Loading FCN model\")\n",
    "model = get_model(\"e2mip://fcn\", device=device)\n",
    "\n",
    "print(\"Loading precipitation model\")\n",
    "package = PrecipitationAFNO.load_package()\n",
    "diagnostic = PrecipitationAFNO.load_diagnostic(package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to wrap the prognostic model with the Diagnostic Time loop.\n",
    "Essentially this adds the execution of the diagnostic model on top of the forecast\n",
    "model iterator. This will add the total preciptation field (`tp`) to the output data\n",
    "which can the be further processed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from earth2mip.diagnostic import DiagnosticTimeLoop\n",
    "\n",
    "model_diagnostic = DiagnosticTimeLoop(diagnostics=[diagnostic], model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference\n",
    "With the diagnostic time loop created the final steps are to create the data source\n",
    "and run inference. For this example we will use the CDS data source again. Its assumed\n",
    "your CDS API key is already set up. Reference the [first example](https://nvidia.github.io/earth2mip/examples/01_ensemble_inference.html#set-up)\n",
    "for additional information. We will use the basic inference workflow which returns a\n",
    "Xarray dataset we will save to netCDF.\n",
    "\n",
    "**TODO**: let user do rain forecast for Munich using GFS for next couple of days.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from earth2mip.inference_ensemble import run_basic_inference\n",
    "from earth2mip.initial_conditions import cds, gfs, hdf5\n",
    "\n",
    "print(\"Constructing initializer data source\")\n",
    "dat_source = 'cds' # 'cds', 'gfs'\n",
    "\n",
    "if dat_source == 'gfs':\n",
    "    data_source = gfs.DataSource(model.in_channel_names)\n",
    "    time = datetime.datetime(2024, 4, 9)\n",
    "elif dat_source == 'cds':\n",
    "    data_source = cds.DataSource(model.in_channel_names)\n",
    "    time = datetime.datetime(2017, 8, 24, 12)\n",
    "elif dat_source == 'hdf5':\n",
    "    h5_folder = '/e2ws_data/era5_73var'\n",
    "    data_source = hdf5.DataSource.from_path(\n",
    "        root=h5_folder, channel_names=model.in_channel_names\n",
    "    )\n",
    "    time = datetime.datetime(2017, 8, 24, 12)\n",
    "\n",
    "print(\"Running inference\")\n",
    "output_dir = \"outputs/04_diagnostic_precip\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "ds = run_basic_inference(\n",
    "    model_diagnostic,\n",
    "    n=36,\n",
    "    data_source=data_source,\n",
    "    time=time,\n",
    ")\n",
    "ds.to_netcdf(os.path.join(output_dir, \"precipitation_afno.nc\"))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "With inference complete we can do some post processing on our predictions. Lets first\n",
    "visualize the total precipitation and total column water vapor for a few days.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This partiulcar date was selected for inference due to an atmopsheric river occuring\n",
    "over the west coast of the United States. Lets plot the total precipitation that\n",
    "occured over San Francisco.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "location = 'munich' # 'munich', 'san francisco'\n",
    "\n",
    "if location == 'san francisco':\n",
    "    loc_lat, loc_lon = 37.75, 237.5 # Lon is [0, 360]\n",
    "elif location == 'munich':\n",
    "    loc_lat, loc_lon = 48., 11.5\n",
    "elif location == 'houston':\n",
    "    loc_lat, loc_lon = 29.75, 264.75 # 84.75\n",
    "else:\n",
    "    raise ValueError(f'region {location} not implemented.')\n",
    "\n",
    "plt.close(\"all\")\n",
    "# Open dataset from saved NetCDFs\n",
    "ds = xr.open_dataarray(os.path.join(output_dir, \"precipitation_afno.nc\"))\n",
    "tp = ds.sel(channel=\"tp\", lat=loc_lat, lon=loc_lon)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(pd.to_datetime(tp.coords[\"time\"]), tp.values*1000)\n",
    "plt.title(f\"{location} (lat: {loc_lat}N lon: {loc_lon}E)\")\n",
    "plt.ylabel(\"Total Precipitation (mm)\")\n",
    "plt.savefig(f\"{output_dir}/tp.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The land fall of the atmosphric river is very clear here, lets have a look at the\n",
    "regional contour of the bay area to better understand the structure of this event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "# Open dataset from saved NetCDFs\n",
    "ds = xr.open_dataarray(os.path.join(output_dir, \"precipitation_afno.nc\"))\n",
    "nsteps = 4\n",
    "proj = ccrs.AlbersEqualArea(central_latitude=loc_lat, central_longitude=loc_lon)\n",
    "fig, ax = plt.subplots(\n",
    "    1,\n",
    "    nsteps,\n",
    "    figsize=(20, 6.5),\n",
    "    subplot_kw={\"projection\": proj},\n",
    "    gridspec_kw={\"wspace\": 0.05, \"hspace\": 0.007},\n",
    ")\n",
    "if nsteps == 1:\n",
    "    ax = [ax]\n",
    "\n",
    "for step in range(nsteps):\n",
    "    i = step + 3\n",
    "    tp = ds[i, 0].sel(channel=\"tp\")\n",
    "\n",
    "    ax[step].add_feature(cartopy.feature.OCEAN, zorder=0)\n",
    "    ax[step].add_feature(cartopy.feature.LAND, zorder=0)\n",
    "    ax[step].add_feature(cartopy.feature.COASTLINE,lw=.5)\n",
    "    ax[step].add_feature(cartopy.feature.RIVERS,lw=.5)\n",
    "    ax[step].add_feature(cartopy.feature.BORDERS, linewidth=0.6, edgecolor='dimgray')\n",
    "\n",
    "    masked_data = np.ma.masked_where(tp.values < 0.001, tp.values)\n",
    "    img = ax[step].pcolormesh(\n",
    "        ds.lon,\n",
    "        ds.lat,\n",
    "        1000 * masked_data,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        cmap=\"plasma\",\n",
    "        vmin=0,\n",
    "        vmax=10,\n",
    "    )\n",
    "    ax[step].set_title(pd.to_datetime(ds.coords[\"time\"])[i])\n",
    "    ax[step].coastlines(color=\"k\")\n",
    "    ax[step].set_extent([loc_lon-10., loc_lon+10., loc_lat-7.5, loc_lat+7.5], ccrs.PlateCarree())\n",
    "    if step == nsteps-1:\n",
    "        plt.colorbar(img, ax=ax, shrink=.3, orientation=\"horizontal\",)\n",
    "\n",
    "\n",
    "ax[0].text(\n",
    "    -0.07,\n",
    "    0.55,\n",
    "    \"Total Precipitation (mm)\",\n",
    "    va=\"bottom\",\n",
    "    ha=\"center\",\n",
    "    rotation=\"vertical\",\n",
    "    rotation_mode=\"anchor\",\n",
    "    transform=ax[0].transAxes,\n",
    ")\n",
    "plt.tight_layout\n",
    "plt.savefig(f\"{output_dir}/diagnostic_bay_area_tp.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the introductory notebook on running diagnostic models. Diangostic\n",
    "models are signifcantly more cheap to train and more flexible for difference usecases.\n",
    "In later examples, we will explore using these models of various other tasks.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
